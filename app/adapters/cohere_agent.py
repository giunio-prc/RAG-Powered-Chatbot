import logging

from dotenv import load_dotenv
from langchain.prompts import (
    ChatPromptTemplate,
    HumanMessagePromptTemplate,
    SystemMessagePromptTemplate,
)
from langchain.schema import StrOutputParser
from langchain_cohere import ChatCohere
from langchain_core.runnables import RunnableSequence

from app.interfaces.agent import AIAgentInterface

load_dotenv()


logger = logging.getLogger(__name__)


class CohereAgent(AIAgentInterface):
    chain: RunnableSequence

    def __init__(self):
        """
        Initializes the CohereAgent with a chat model, prompt templates, and a runnable response chain.
        """
        self.model = ChatCohere(model="command-r-plus")
        system_message_prompt = SystemMessagePromptTemplate.from_template(
            self.prompt_template
        )
        human_message_prompt = HumanMessagePromptTemplate.from_template(
            template="{question}"
        )
        chat_prompt_template = ChatPromptTemplate.from_messages(
            [system_message_prompt, human_message_prompt]
        )
        self.chain = chat_prompt_template | self.model | StrOutputParser()

    async def query_with_context(self, question: str, context: str) -> str:
        """
        Asynchronously queries the language model with a question and additional context, returning the generated response.

        Parameters:
            question (str): The input question to be answered.
            context (str): Supplementary information to provide context for the question.

        Returns:
            str: The response generated by the language model.
        """
        logger.debug("Question: %s", question)
        logger.debug("Context: %s", context)
        response = await self.chain.ainvoke({"question": question, "context": context})
        return response
